<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>AI on 2026 AIA台灣人工智慧學校分享平台</title>
    <link>https://taiwan-ai-academy.github.io/categories/ai/</link>
    <description>Recent content in AI on 2026 AIA台灣人工智慧學校分享平台</description>
    <generator>Hugo</generator>
    <language>zh-tw</language>
    <lastBuildDate>Thu, 22 Jan 2026 10:57:34 +0800</lastBuildDate>
    <atom:link href="https://taiwan-ai-academy.github.io/categories/ai/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>RAG 不只要找對答案還要找對「地方」：UniversalRAG</title>
      <link>https://taiwan-ai-academy.github.io/posts/universalrag-find-the-right-place/</link>
      <pubDate>Thu, 22 Jan 2026 10:57:34 +0800</pubDate>
      <guid>https://taiwan-ai-academy.github.io/posts/universalrag-find-the-right-place/</guid>
      <description>&lt;p&gt;大家對 RAG（檢索增強生成）應該不陌生，現在的痛點在於資料不只有純文字還有圖片、表格跟影片。&#xA;目前主流的 RAG 做法，通常是把所有類型的資料全部轉成 Embedding，丟進向量資料庫。&#xA;但把不同格式的資料硬湊在同一個空間搜尋，其實效果並不好，很容易出現偏食的狀況。&lt;/p&gt;</description>
    </item>
    <item>
      <title>SciSciGPT AI 協作工具在《Nature Computational Science》亮相</title>
      <link>https://taiwan-ai-academy.github.io/posts/sciscigpt-nature-computational-science/</link>
      <pubDate>Tue, 20 Jan 2026 17:15:35 +0800</pubDate>
      <guid>https://taiwan-ai-academy.github.io/posts/sciscigpt-nature-computational-science/</guid>
      <description>&lt;p&gt;科研數據這麼複雜，專家分工又太細，能不能開發出一種 AI，讓研究人員不需要變成數據工程師，也能輕鬆搞定研究流程？&lt;/p&gt;</description>
    </item>
    <item>
      <title>由北航、阿里巴巴、字節跳動、上海 AI 實驗室等全球頂尖機構聯合發布的重磅綜述: From Code Foundation Models to Agents and Applications</title>
      <link>https://taiwan-ai-academy.github.io/posts/code-foundation-models-to-agents-guide/</link>
      <pubDate>Wed, 10 Dec 2025 13:09:30 +0800</pubDate>
      <guid>https://taiwan-ai-academy.github.io/posts/code-foundation-models-to-agents-guide/</guid>
      <description>&lt;p&gt;這是一本 AI Coding 領域的「百科全書」與「實戰手冊」。它梳理了從 2021 年到 2025 年代碼大模型（Code LLMs）的爆炸式增長，揭示 AI 如何從簡單的程式碼補全工具，進化為能夠獨立解決複雜軟體工程問題的智慧體。&lt;/p&gt;</description>
    </item>
    <item>
      <title>Meta新一代影像理解模型</title>
      <link>https://taiwan-ai-academy.github.io/posts/meta-new-image-understanding-model/</link>
      <pubDate>Sun, 30 Nov 2025 10:01:43 +0800</pubDate>
      <guid>https://taiwan-ai-academy.github.io/posts/meta-new-image-understanding-model/</guid>
      <description>&lt;p&gt;視覺場景中尋找並分割任何物體的能力，是多模態人工智慧的基礎要素。SAM 3 讓這項能力從「單一物體」跨越到「概念級」的偵測與追蹤。&lt;/p&gt;</description>
    </item>
    <item>
      <title>OpenAI 研究人員介紹一種訓練 Weight-Sparse Transformers 的典範</title>
      <link>https://taiwan-ai-academy.github.io/posts/openai-weight-sparse-transformers/</link>
      <pubDate>Thu, 27 Nov 2025 09:00:00 +0800</pubDate>
      <guid>https://taiwan-ai-academy.github.io/posts/openai-weight-sparse-transformers/</guid>
      <description>&lt;p&gt;在可解釋性領域中，一個核心目標是找出大型語言模型（LLM）中，人類可以理解的內部計算迴路。OpenAI 研究人員提出的 weight-sparse Transformer 典範，嘗試在訓練階段就強制模型形成結構化的稀疏權重，讓路徑與子模組的功能更可視、可解釋。具體作法是訓練一種權重稀疏化的 Transformer，使絕大多數權重為零；這樣可簡化計算，並引導模型把概念表示分散到多個殘差通道，最終得到較可解釋的計算迴路。&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
